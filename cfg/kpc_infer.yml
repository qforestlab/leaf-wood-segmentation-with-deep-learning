dataset:
  dataset_path: /mnt/c/Users/wavdnbro/OneDrive - UGent/Documents/spacetwin/datasets/cax2023 # Parent directory of test_dir and test_result_folder
  test_dir: PB_23_trees # Directory with you point clouds (npy, txt or ply)
  test_result_folder: results_tmp # Directory where leaf-wood separated results are stored.
model:
  name: KPConv # Name of network
  ckpt_path: ./model_weights/weights_kpconv.pth # Continue from this checkpoint (=saved weights)
  first_subsampling_dl: 0.02 # Point cloud downsampling to this voxel resolution prior to network input
  min_in_points: 10000 # Number of points around a center point sampled, using furthest dist sampling to step through the whole point cloud
  in_points_dim: 3 # Three input channels for the XYZ coordinates
  in_features_dim: 3 # Number of features = in_points_dim --> only XYZ coordinates
  num_classes: 2 # Number of output classes (leaf + wood)
  lbl_values: [0, 1] # Label values (leaf=0, wood=1)
  ignored_label_inds: [] # Ignored classes during training. Not used here but argument is required.
  augment:
    recenter:
      dim: [0, 1, 2] # Recenter all 3 dimensions around (0,0,0) for each subsample
pipeline:
  device: 'cuda:0' # 'cuda:0' or 'cpu'
  batch_size: 3
